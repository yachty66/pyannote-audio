{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.7.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1920, 1080], 'bitrate': 2353, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.19.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 28.03, 'bitrate': 2488, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1920, 1080], 'video_bitrate': 2353, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 28.03, 'video_n_frames': 672}\n",
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i output.mp4 -loglevel error -f image2pipe -vf scale=1920:1080 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "from moviepy import *\n",
    "\n",
    "# Load the video file\n",
    "video = VideoFileClip(\"output.mp4\")\n",
    "\n",
    "# Extract the audio and save it as WAV\n",
    "video.audio.write_audiofile(\"audio.wav\")\n",
    "\n",
    "# Close the video file to free up resources\n",
    "video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.4s stop=0.5s speaker_SPEAKER_03\n",
      "start=0.5s stop=3.0s speaker_SPEAKER_00\n",
      "start=3.1s stop=3.4s speaker_SPEAKER_03\n",
      "start=3.9s stop=6.3s speaker_SPEAKER_03\n",
      "start=6.3s stop=6.3s speaker_SPEAKER_00\n",
      "start=6.3s stop=6.6s speaker_SPEAKER_03\n",
      "start=6.4s stop=9.2s speaker_SPEAKER_00\n",
      "start=6.6s stop=7.8s speaker_SPEAKER_04\n",
      "start=9.6s stop=9.7s speaker_SPEAKER_03\n",
      "start=9.7s stop=12.4s speaker_SPEAKER_04\n",
      "start=13.1s stop=19.0s speaker_SPEAKER_04\n",
      "start=17.4s stop=17.4s speaker_SPEAKER_02\n",
      "start=17.4s stop=17.7s speaker_SPEAKER_01\n",
      "start=17.7s stop=17.7s speaker_SPEAKER_02\n",
      "start=19.0s stop=19.1s speaker_SPEAKER_02\n",
      "start=19.1s stop=28.0s speaker_SPEAKER_01\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i am blocked right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.8.6 to v2.5.1. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../root/.cache/torch/pyannote/models--pyannote--separation-ami-1.0/snapshots/4d38e95cfd067c894b8b60b00761831fb01e4a8c/pytorch_model.bin`\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/speechbrain/utils/autocast.py:68: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n"
     ]
    }
   ],
   "source": [
    "#now i need to make the \n",
    "# instantiate the pipeline\n",
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speech-separation-ami-1.0\",\n",
    "    use_auth_token=\"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\")  # using your token from earlier\n",
    "\n",
    "# run the pipeline on the audio file\n",
    "diarization, sources = pipeline(\"audio.wav\")\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n",
    "\n",
    "# dump sources to disk as SPEAKER_XX.wav files\n",
    "import scipy.io.wavfile\n",
    "for s, speaker in enumerate(diarization.labels()):\n",
    "    scipy.io.wavfile.write(f'SPEAKER_{s}.wav', 16000, sources.data[:,s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
