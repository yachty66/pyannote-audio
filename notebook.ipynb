{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.7.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1920, 1080], 'bitrate': 2353, 'fps': 23.976023976023978, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.19.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 128, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 28.03, 'bitrate': 2488, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1920, 1080], 'video_bitrate': 2353, 'video_fps': 23.976023976023978, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 128, 'video_duration': 28.03, 'video_n_frames': 672}\n",
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i output.mp4 -loglevel error -f image2pipe -vf scale=1920:1080 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Writing audio in audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "from moviepy import *\n",
    "\n",
    "# Load the video file\n",
    "video = VideoFileClip(\"output.mp4\")\n",
    "\n",
    "# Extract the audio and save it as WAV\n",
    "video.audio.write_audiofile(\"audio.wav\")\n",
    "\n",
    "# Close the video file to free up resources\n",
    "video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/workspace/pyannote-audio/venv/lib/python3.10/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "File audio.wav does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspace/pyannote-audio/notebook.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B213.181.111.2/workspace/pyannote-audio/notebook.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m pipeline\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B213.181.111.2/workspace/pyannote-audio/notebook.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# apply pretrained pipeline\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B213.181.111.2/workspace/pyannote-audio/notebook.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m diarization \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39maudio.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B213.181.111.2/workspace/pyannote-audio/notebook.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# print the result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B213.181.111.2/workspace/pyannote-audio/notebook.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m turn, _, speaker \u001b[39min\u001b[39;00m diarization\u001b[39m.\u001b[39mitertracks(yield_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/workspace/pyannote-audio/venv/lib/python3.10/site-packages/pyannote/audio/core/pipeline.py:322\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    314\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mA pipeline must be instantiated with `pipeline.instantiate(paramaters)` before it can be applied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    315\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTried to use parameters provided by `pipeline.default_parameters()` but those are not compatible. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    318\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe pipeline has been automatically instantiated with \u001b[39m\u001b[39m{\u001b[39;00mdefault_parameters\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 322\u001b[0m file \u001b[39m=\u001b[39m Audio\u001b[39m.\u001b[39;49mvalidate_file(file)\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpreprocessors\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    325\u001b[0m     file \u001b[39m=\u001b[39m ProtocolFile(file, lazy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessors)\n",
      "File \u001b[0;32m/workspace/pyannote-audio/venv/lib/python3.10/site-packages/pyannote/audio/core/io.py:194\u001b[0m, in \u001b[0;36mAudio.validate_file\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    192\u001b[0m     path \u001b[39m=\u001b[39m Path(file[\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    193\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mis_file():\n\u001b[0;32m--> 194\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile \u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m     file\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39muri\u001b[39m\u001b[39m\"\u001b[39m, path\u001b[39m.\u001b[39mstem)\n\u001b[1;32m    198\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: File audio.wav does not exist"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "\n",
    "# send pipeline to GPU (when available)\n",
    "import torch\n",
    "pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")\n",
    "# start=0.2s stop=1.5s speaker_0\n",
    "# start=1.8s stop=3.9s speaker_1\n",
    "# start=4.2s stop=5.7s speaker_0\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
