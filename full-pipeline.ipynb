{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hello my name is and i am going to be in the middle of the name of the name and i am going to be in the middle of ther \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i need to make the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the problem is that i dont have the right results i need. i want to have at least all speakers seprated correcrtly but currently this is not true\n",
    "#so all i can do now is to \n",
    "#i am unsure how to deal with that tbh \n",
    "#i dont know how to deal with that shit, damn i just dont know\n",
    "#i wish in knew so that i could do somethign against it but i just dont know\n",
    "\n",
    "#i think the only way would be to detect speech and then label it by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/projects/worldwomanmap/env/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments saved to segments.json\n",
      "Audio segments saved in speaker_segments/\n",
      "\n",
      "Example of how to review and assign speakers:\n",
      "1. Open segments.json to see all segments\n",
      "2. Listen to each segment using the audio_file path\n",
      "3. Edit the 'speaker' field in segments.json to assign the correct speaker\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import json\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory for audio segments\n",
    "output_dir = \"speaker_segments\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get the segments first\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"\")\n",
    "\n",
    "pipeline.to(torch.device(\"cpu\"))\n",
    "\n",
    "# Load the full audio file\n",
    "audio, sample_rate = sf.read(\"audio.wav\")\n",
    "\n",
    "# Get diarization results\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# Convert segments to a simple format and save audio segments\n",
    "segments = []\n",
    "for i, (turn, _, speaker) in enumerate(diarization.itertracks(yield_label=True)):\n",
    "    # Calculate start and end samples\n",
    "    start_sample = int(turn.start * sample_rate)\n",
    "    end_sample = int(turn.end * sample_rate)\n",
    "    \n",
    "    # Extract audio segment\n",
    "    segment_audio = audio[start_sample:end_sample]\n",
    "    \n",
    "    # Create filename for this segment\n",
    "    segment_filename = f\"segment_{i:03d}_{turn.start:.2f}_{turn.end:.2f}.wav\"\n",
    "    segment_path = os.path.join(output_dir, segment_filename)\n",
    "    \n",
    "    # Save audio segment\n",
    "    sf.write(segment_path, segment_audio, sample_rate)\n",
    "    \n",
    "    # Add to segments list\n",
    "    segments.append({\n",
    "        'start': float(turn.start),\n",
    "        'end': float(turn.end),\n",
    "        'speaker': speaker,\n",
    "        'audio_file': segment_path,\n",
    "        'segment_id': i\n",
    "    })\n",
    "\n",
    "# Save to JSON file\n",
    "with open('segments.json', 'w') as f:\n",
    "    json.dump(segments, f, indent=2)\n",
    "\n",
    "print(f\"Segments saved to segments.json\")\n",
    "print(f\"Audio segments saved in {output_dir}/\")\n",
    "print(\"\\nExample of how to review and assign speakers:\")\n",
    "print(\"1. Open segments.json to see all segments\")\n",
    "print(\"2. Listen to each segment using the audio_file path\")\n",
    "print(\"3. Edit the 'speaker' field in segments.json to assign the correct speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/projects/worldwomanmap/env/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.4s stop=0.5s speaker_SPEAKER_02\n",
      "start=0.5s stop=3.0s speaker_SPEAKER_01\n",
      "start=3.1s stop=3.4s speaker_SPEAKER_02\n",
      "start=3.9s stop=6.6s speaker_SPEAKER_02\n",
      "start=6.3s stop=9.2s speaker_SPEAKER_01\n",
      "start=6.6s stop=7.8s speaker_SPEAKER_03\n",
      "start=9.6s stop=9.7s speaker_SPEAKER_02\n",
      "start=9.7s stop=12.4s speaker_SPEAKER_03\n",
      "start=13.1s stop=19.0s speaker_SPEAKER_03\n",
      "start=17.4s stop=17.7s speaker_SPEAKER_00\n",
      "start=19.0s stop=28.0s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"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\")\n",
    "\n",
    "# send pipeline to CPU instead of GPU\n",
    "import torch\n",
    "pipeline.to(torch.device(\"cpu\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# print the result  \n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing SPEAKER_02...\n",
      "Using filter: volume=enable='between(t,0.41909375000000004,0.4697187500000001)+between(t,3.10221875,3.4397187500000004)+between(t,3.87846875,6.61221875)+between(t,9.649718750000002,9.66659375)':volume=1,volume=enable='not(between(t,0.41909375000000004,0.4697187500000001)+between(t,3.10221875,3.4397187500000004)+between(t,3.87846875,6.61221875)+between(t,9.649718750000002,9.66659375))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_02.wav\n",
      "\n",
      "Processing SPEAKER_01...\n",
      "Using filter: volume=enable='between(t,0.4697187500000001,2.95034375)+between(t,6.257843750000001,9.19409375)':volume=1,volume=enable='not(between(t,0.4697187500000001,2.95034375)+between(t,6.257843750000001,9.19409375))':volume=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x11e107ec0] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_02.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x11e1087c0] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=4.28e+03x    \n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x152004320] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_01.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x152004570] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=8e+03x    \n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x124104320] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_03.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x1241045c0] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=7.12e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: separated_speakers/speaker_SPEAKER_01.wav\n",
      "\n",
      "Processing SPEAKER_03...\n",
      "Using filter: volume=enable='between(t,6.61221875,7.844093750000001)+between(t,9.66659375,12.400343750000001)+between(t,13.058468750000003,18.99846875)':volume=1,volume=enable='not(between(t,6.61221875,7.844093750000001)+between(t,9.66659375,12.400343750000001)+between(t,13.058468750000003,18.99846875))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_03.wav\n",
      "\n",
      "Processing SPEAKER_00...\n",
      "Using filter: volume=enable='between(t,17.36159375,17.69909375)+between(t,18.99846875,27.992843750000002)':volume=1,volume=enable='not(between(t,17.36159375,17.69909375)+between(t,18.99846875,27.992843750000002))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_00.wav\n",
      "\n",
      "All speaker files have been created in separated_speakers!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x11e904f30] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_00.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x11e905220] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=8.87e+03x    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Specify your output directory\n",
    "output_dir = \"separated_speakers\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Group segments by speaker\n",
    "speaker_segments = defaultdict(list)\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    speaker_segments[speaker].append({\n",
    "        'start': turn.start,\n",
    "        'end': turn.end\n",
    "    })\n",
    "\n",
    "input_file = \"audio.wav\"  # Your input audio file\n",
    "\n",
    "# Process each speaker\n",
    "for speaker, segments in speaker_segments.items():\n",
    "    # Create the volume filter expression\n",
    "    volume_expr = []\n",
    "    for segment in segments:\n",
    "        volume_expr.append(f\"between(t,{segment['start']},{segment['end']})\")\n",
    "\n",
    "    # Combine all segments with OR operator (+)\n",
    "    filter_expression = f\"volume=enable='{'+'.join(volume_expr)}':volume=1,volume=enable='not({'+'.join(volume_expr)})':volume=0\"\n",
    "\n",
    "    # Create output file path in the specified directory\n",
    "    output_file = os.path.join(output_dir, f\"speaker_{speaker}.wav\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-i\", input_file,\n",
    "        \"-af\", filter_expression,\n",
    "        \"-c:a\", \"pcm_s16le\",  # Use WAV format\n",
    "        \"-vn\",  # Remove video stream\n",
    "        output_file\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nProcessing {speaker}...\")\n",
    "    print(f\"Using filter: {filter_expression}\")\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Created file: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing {speaker}: {e}\")\n",
    "\n",
    "print(f\"\\nAll speaker files have been created in {output_dir}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
