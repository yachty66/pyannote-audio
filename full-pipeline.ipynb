{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/projects/worldwomanmap/env/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segments saved to segments.json\n",
      "Audio segments saved in speaker_segments/\n",
      "\n",
      "Example of how to review and assign speakers:\n",
      "1. Open segments.json to see all segments\n",
      "2. Listen to each segment using the audio_file path\n",
      "3. Edit the 'speaker' field in segments.json to assign the correct speaker\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import torch\n",
    "import json\n",
    "import soundfile as sf\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create output directory for audio segments\n",
    "output_dir = \"speaker_segments\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get the segments first\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"\")\n",
    "\n",
    "pipeline.to(torch.device(\"cpu\"))\n",
    "\n",
    "# Load the full audio file\n",
    "audio, sample_rate = sf.read(\"audio.wav\")\n",
    "\n",
    "# Get diarization results\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# Convert segments to a simple format and save audio segments\n",
    "segments = []\n",
    "for i, (turn, _, speaker) in enumerate(diarization.itertracks(yield_label=True)):\n",
    "    # Calculate start and end samples\n",
    "    start_sample = int(turn.start * sample_rate)\n",
    "    end_sample = int(turn.end * sample_rate)\n",
    "    \n",
    "    # Extract audio segment\n",
    "    segment_audio = audio[start_sample:end_sample]\n",
    "    \n",
    "    # Create filename for this segment\n",
    "    segment_filename = f\"segment_{i:03d}_{turn.start:.2f}_{turn.end:.2f}.wav\"\n",
    "    segment_path = os.path.join(output_dir, segment_filename)\n",
    "    \n",
    "    # Save audio segment\n",
    "    sf.write(segment_path, segment_audio, sample_rate)\n",
    "    \n",
    "    # Add to segments list\n",
    "    segments.append({\n",
    "        'start': float(turn.start),\n",
    "        'end': float(turn.end),\n",
    "        'speaker': speaker,\n",
    "        'audio_file': segment_path,\n",
    "        'segment_id': i,\n",
    "        'is_overlapping': False\n",
    "    })\n",
    "\n",
    "# Save to JSON file\n",
    "with open('segments.json', 'w') as f:\n",
    "    json.dump(segments, f, indent=2)\n",
    "\n",
    "print(f\"Segments saved to segments.json\")\n",
    "print(f\"Audio segments saved in {output_dir}/\")\n",
    "print(\"\\nExample of how to review and assign speakers:\")\n",
    "print(\"1. Open segments.json to see all segments\")\n",
    "print(\"2. Listen to each segment using the audio_file path\")\n",
    "print(\"3. Edit the 'speaker' field in segments.json to assign the correct speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting conversion for files in 'speaker_segments'...\n",
      "Converting 'segment_009_9.67_12.40.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_009_9.67_12.40.wav'.\n",
      "Converting 'segment_013_17.68_17.70.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_013_17.68_17.70.wav'.\n",
      "Converting 'segment_014_19.03_19.07.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_014_19.03_19.07.wav'.\n",
      "Converting 'segment_010_13.06_19.03.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_010_13.06_19.03.wav'.\n",
      "Converting 'segment_007_6.61_7.84.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_007_6.61_7.84.wav'.\n",
      "Converting 'segment_012_17.40_17.68.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_012_17.40_17.68.wav'.\n",
      "Converting 'segment_006_6.36_9.19.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_006_6.36_9.19.wav'.\n",
      "Converting 'segment_008_9.65_9.67.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_008_9.65_9.67.wav'.\n",
      "Converting 'segment_011_17.36_17.40.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_011_17.36_17.40.wav'.\n",
      "Converting 'segment_015_19.07_27.99.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_015_19.07_27.99.wav'.\n",
      "Converting 'segment_002_3.10_3.44.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_002_3.10_3.44.wav'.\n",
      "Converting 'segment_004_6.26_6.29.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_004_6.26_6.29.wav'.\n",
      "Converting 'segment_005_6.29_6.61.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_005_6.29_6.61.wav'.\n",
      "Converting 'segment_001_0.47_2.95.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_001_0.47_2.95.wav'.\n",
      "Converting 'segment_000_0.42_0.47.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_000_0.42_0.47.wav'.\n",
      "Converting 'segment_003_3.88_6.26.wav' from 44100 Hz to 16000 Hz...\n",
      "Successfully converted and saved 'segment_003_3.88_6.26.wav'.\n",
      "\n",
      "Conversion process finished for folder 'speaker_segments'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Directory containing the audio segments\n",
    "input_dir = \"speaker_segments\"\n",
    "target_sr = 16000\n",
    "\n",
    "print(f\"Starting conversion for files in '{input_dir}'...\")\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    # Check if the file is a WAV file\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            # Load the audio file, preserving the original sample rate\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "            \n",
    "            # Check if resampling is needed\n",
    "            if sr != target_sr:\n",
    "                print(f\"Converting '{filename}' from {sr} Hz to {target_sr} Hz...\")\n",
    "                # Resample the audio to 16 kHz\n",
    "                audio_16k = librosa.resample(y=audio, orig_sr=sr, target_sr=target_sr)\n",
    "                \n",
    "                # Overwrite the original file with the resampled audio\n",
    "                sf.write(file_path, audio_16k, target_sr)\n",
    "                print(f\"Successfully converted and saved '{filename}'.\")\n",
    "            else:\n",
    "                print(f\"'{filename}' is already at {target_sr} Hz. Skipping.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{filename}': {e}\")\n",
    "\n",
    "print(f\"\\nConversion process finished for folder '{input_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo need to make speaker separation programmatically possible for now will just use https://modelscope.cn/studios/iic/ClearerVoice-Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "now before assigning the labels to speakers i need to make sure that we dont have audio files where two people speak at the same time\n",
    "\n",
    "so what i need to do is to go to each audio file and check if two people are speaking at the same time\n",
    "\n",
    "then i need to mark this files again - i need to iterate over all of the files and then make the \n",
    "\n",
    "1. generate segments.json\n",
    "2. iterate over each single audio file and check if overlapping speech and set is_overlapping to true\n",
    "3. run each file through speech separation model where overlap is true\n",
    "3. the result needs to be saved in a folder \"separated-audio\" \n",
    "4. then go again to each segment in the file and duplicate for each segment where overlap is true the entry and set speaker and path correctly\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxhager/projects/worldwomanmap/env/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0.4s stop=0.5s speaker_SPEAKER_02\n",
      "start=0.5s stop=3.0s speaker_SPEAKER_01\n",
      "start=3.1s stop=3.4s speaker_SPEAKER_02\n",
      "start=3.9s stop=6.6s speaker_SPEAKER_02\n",
      "start=6.3s stop=9.2s speaker_SPEAKER_01\n",
      "start=6.6s stop=7.8s speaker_SPEAKER_03\n",
      "start=9.6s stop=9.7s speaker_SPEAKER_02\n",
      "start=9.7s stop=12.4s speaker_SPEAKER_03\n",
      "start=13.1s stop=19.0s speaker_SPEAKER_03\n",
      "start=17.4s stop=17.7s speaker_SPEAKER_00\n",
      "start=19.0s stop=28.0s speaker_SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token=\"\")\n",
    "\n",
    "# send pipeline to CPU instead of GPU\n",
    "import torch\n",
    "pipeline.to(torch.device(\"cpu\"))\n",
    "\n",
    "# apply pretrained pipeline\n",
    "diarization = pipeline(\"audio.wav\")\n",
    "\n",
    "# print the result  \n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing SPEAKER_02...\n",
      "Using filter: volume=enable='between(t,0.41909375000000004,0.4697187500000001)+between(t,3.10221875,3.4397187500000004)+between(t,3.87846875,6.61221875)+between(t,9.649718750000002,9.66659375)':volume=1,volume=enable='not(between(t,0.41909375000000004,0.4697187500000001)+between(t,3.10221875,3.4397187500000004)+between(t,3.87846875,6.61221875)+between(t,9.649718750000002,9.66659375))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_02.wav\n",
      "\n",
      "Processing SPEAKER_01...\n",
      "Using filter: volume=enable='between(t,0.4697187500000001,2.95034375)+between(t,6.257843750000001,9.19409375)':volume=1,volume=enable='not(between(t,0.4697187500000001,2.95034375)+between(t,6.257843750000001,9.19409375))':volume=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x11e107ec0] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_02.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x11e1087c0] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=4.28e+03x    \n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x152004320] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_01.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x152004570] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=8e+03x    \n",
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x124104320] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_03.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x1241045c0] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=7.12e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created file: separated_speakers/speaker_SPEAKER_01.wav\n",
      "\n",
      "Processing SPEAKER_03...\n",
      "Using filter: volume=enable='between(t,6.61221875,7.844093750000001)+between(t,9.66659375,12.400343750000001)+between(t,13.058468750000003,18.99846875)':volume=1,volume=enable='not(between(t,6.61221875,7.844093750000001)+between(t,9.66659375,12.400343750000001)+between(t,13.058468750000003,18.99846875))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_03.wav\n",
      "\n",
      "Processing SPEAKER_00...\n",
      "Using filter: volume=enable='between(t,17.36159375,17.69909375)+between(t,18.99846875,27.992843750000002)':volume=1,volume=enable='not(between(t,17.36159375,17.69909375)+between(t,18.99846875,27.992843750000002))':volume=0\n",
      "Created file: separated_speakers/speaker_SPEAKER_00.wav\n",
      "\n",
      "All speaker files have been created in separated_speakers!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with Apple clang version 16.0.0 (clang-1600.0.26.6)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1.1_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "[aist#0:0/pcm_s16le @ 0x11e904f30] Guessed Channel Layout: stereo\n",
      "Input #0, wav, from 'audio.wav':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.1.100\n",
      "  Duration: 00:00:28.03, bitrate: 1411 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'separated_speakers/speaker_SPEAKER_00.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
      "      Metadata:\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0x11e905220] video:0KiB audio:4829KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001578%\n",
      "size=    4829KiB time=00:00:28.03 bitrate=1411.2kbits/s speed=8.87e+03x    \n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Specify your output directory\n",
    "output_dir = \"separated_speakers\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Group segments by speaker\n",
    "speaker_segments = defaultdict(list)\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    speaker_segments[speaker].append({\n",
    "        'start': turn.start,\n",
    "        'end': turn.end\n",
    "    })\n",
    "\n",
    "input_file = \"audio.wav\"  # Your input audio file\n",
    "\n",
    "# Process each speaker\n",
    "for speaker, segments in speaker_segments.items():\n",
    "    # Create the volume filter expression\n",
    "    volume_expr = []\n",
    "    for segment in segments:\n",
    "        volume_expr.append(f\"between(t,{segment['start']},{segment['end']})\")\n",
    "\n",
    "    # Combine all segments with OR operator (+)\n",
    "    filter_expression = f\"volume=enable='{'+'.join(volume_expr)}':volume=1,volume=enable='not({'+'.join(volume_expr)})':volume=0\"\n",
    "\n",
    "    # Create output file path in the specified directory\n",
    "    output_file = os.path.join(output_dir, f\"speaker_{speaker}.wav\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-i\", input_file,\n",
    "        \"-af\", filter_expression,\n",
    "        \"-c:a\", \"pcm_s16le\",  # Use WAV format\n",
    "        \"-vn\",  # Remove video stream\n",
    "        output_file\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nProcessing {speaker}...\")\n",
    "    print(f\"Using filter: {filter_expression}\")\n",
    "    try:\n",
    "        subprocess.run(cmd, check=True)\n",
    "        print(f\"Created file: {output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing {speaker}: {e}\")\n",
    "\n",
    "print(f\"\\nAll speaker files have been created in {output_dir}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
